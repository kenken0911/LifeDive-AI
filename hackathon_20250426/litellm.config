# LiteLLM モデル設定ファイル (サンプル)
# 実際のAPIキーは環境変数から読み込みます。
# このファイルをリポジトリに含める場合は、APIキーに関する情報を削除またはマスクしてください。

model_list:
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      # 環境変数からOpenAI APIキーを読み込みます (例: OPENAI_API_KEY)
      api_key: os.environ/<YOUR_OPENAI_API_KEY_ENV_VAR>

  - model_name: gpt-4o-mini-transcribe
    litellm_params:
      model: openai/gpt-4o-mini-transcribe
      api_key: os.environ/<YOUR_OPENAI_API_KEY_ENV_VAR> # 上記と同じ環境変数を使用

  - model_name: whisper-1
    litellm_params:
      model: openai/whisper-1
      api_key: os.environ/<YOUR_OPENAI_API_KEY_ENV_VAR> # 上記と同じ環境変数を使用

  - model_name: gpt-4o-audio-preview # OpenAI gpt-4o-audio-preview
    litellm_params:
      model: openai/gpt-4o-audio-preview
      api_key: os.environ/<YOUR_OPENAI_API_KEY_ENV_VAR> # 上記と同じ環境変数を使用

  - model_name: Meta-Llama-3.2-3B-Instruct
    litellm_params:
      model: sambanova/Meta-Llama-3.2-3B-Instruct
      # 環境変数からSambanova APIキーを読み込みます (例: SAMBANOVA_API_KEY)
      api_key: os.environ/<YOUR_SAMBANOVA_API_KEY_ENV_VAR>

  - model_name: Meta-Llama-3.3-70B-Instruct
    litellm_params:
      model: sambanova/Meta-Llama-3.3-70B-Instruct
      api_key: os.environ/<YOUR_SAMBANOVA_API_KEY_ENV_VAR> # 上記と同じ環境変数を使用

  - model_name: Llama-4-Maverick-17B-128E-Instruct
    litellm_params:
      model: sambanova/Llama-4-Maverick-17B-128E-Instruct
      api_key: os.environ/<YOUR_SAMBANOVA_API_KEY_ENV_VAR> # 上記と同じ環境変数を使用
    model_info:
      supports_vision: True        # set supports_vision to True so /model/info returns this attribute as True

  - model_name: Whisper-Large-v3
    litellm_params:
      model: sambanova/Whisper-Large-v3
      api_key: os.environ/<YOUR_SAMBANOVA_API_KEY_ENV_VAR> # 上記と同じ環境変数を使用
      default_params:
        language: "ja"  # デフォルト言語を日本語に設定
    model_info:
      supports_audio_input: True        # set supports_audio_input to True so /model/info returns this attribute as True

  - model_name: gemini-2.0-flash
    litellm_params:
      model: gemini/gemini-2.0-flash-exp
      # 環境変数からGemini APIキーを読み込みます (例: GEMINI_API_KEY)
      api_key: os.environ/<YOUR_GEMINI_API_KEY_ENV_VAR>

  # 画像生成モデル
  - model_name: dall-e-3
    litellm_params:
      model: openai/dall-e-3
      api_key: os.environ/<YOUR_OPENAI_API_KEY_ENV_VAR> # OpenAIキーを使用
    model_info:
      supports_image_generation: True

  # Text-to-Speech モデル
  - model_name: tts-1
    litellm_params:
      model: openai/tts-1
      api_key: os.environ/<YOUR_OPENAI_API_KEY_ENV_VAR> # OpenAIキーを使用
    model_info:
      supports_tts: True

  - model_name: tts-1-hd
    litellm_params:
      model: openai/tts-1-hd
      api_key: os.environ/<YOUR_OPENAI_API_KEY_ENV_VAR> # OpenAIキーを使用
    model_info:
      supports_tts: True

# ログ設定 (この部分は通常、公開しても問題ありません)
log_config:
  request_log_path: ./logs
  log_level: debug
  log_requests: true
  log_responses: true
  verbose: true

# リクエスト/レスポンスのトラッキング設定 (この部分も通常、公開しても問題ありません)
callbacks:
  - callback_type: local_log
    options:
      request_log_path: ./logs